{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Dask Icon](images/dask_horizontal_black.gif \"Dask Icon\")\n",
    "![Pandas Icon](images/pandas_logo.png \"Pandas Icon\")\n",
    "\n",
    "# Gotcha's from Pandas to Dask\n",
    "\n",
    "https://github.com/sephib/dask_pyconil2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This notebook highlights some key differences when transfering code from `Pandas` to run in a `Dask` environment.  \n",
    "Most issues have a link to the [Dask documentation](https://docs.dask.org/en/latest/) for additional information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Agenda  \n",
    "1. Intro to `Dask` framework\n",
    "2. Basic setup\n",
    "3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Dask Icon](images/dask_horizontal_black.gif \"Dask Icon\")\n",
    "\n",
    "Dask is a flexible library for parallel computing in Python.\n",
    "\n",
    "![Dask Framework](images/dask_graph_outline.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "\n",
    "Dask is composed of two parts:\n",
    "\n",
    "1. *Dynamic task scheduling* optimized for computation. This is similar to Airflow, Luigi, Celery, or Make, but optimized for interactive computational workloads.\n",
    "2. *“Big Data” collections* like parallel arrays, dataframes, and lists that extend common interfaces like NumPy, Pandas, or Python iterators to larger-than-memory or distributed environments. These parallel collections run on top of dynamic task schedulers.\n",
    "\n",
    "[link to documentation](https://docs.dask.org/en/latest/)\n",
    "\n",
    "Dask emphasizes the following virtues:\n",
    "\n",
    "* Familiar: Provides parallelized NumPy array and Pandas DataFrame objects\n",
    "* Flexible: Provides a task scheduling interface for more custom workloads and integration with other projects.\n",
    "* Native: Enables distributed computing in pure Python with access to the PyData stack.\n",
    "* Fast: Operates with low overhead, low latency, and minimal serialization necessary for fast numerical algorithms\n",
    "* Scales up: Runs resiliently on clusters with 1000s of cores\n",
    "* Scales down: Trivial to set up and run on a laptop in a single process\n",
    "* Responsive: Designed with interactive computing in mind, it provides rapid feedback and diagnostics to aid humans\n",
    "\n",
    "\n",
    "See the [dask.distributed documentation (separate website)](https://distributed.dask.org/en/latest/) for more technical information on Dask’s distributed scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask versoin: 1.2.2\n",
      "Pandas versoin: 0.24.2\n"
     ]
    }
   ],
   "source": [
    "# since Dask is activly beeing developed - the current example is running with the below version\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "print(f'Dask versoin: {dask.__version__}')\n",
    "print(f'Pandas versoin: {pd.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dask `Distributed` scheduler  \n",
    "* When running code within a script use `context manager`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python   \n",
    "import dask.dataframe as dd  \n",
    "from dask.distributed import Client  \n",
    "\n",
    "df = dd.read_csv(...) # do something\n",
    "``` \n",
    "vs\n",
    "```python   \n",
    "if __name__ == '__main__':\n",
    "    with Client() as client:\n",
    "        df = dd.read_csv(...) # do something\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "* see question in [stack overflow](https://stackoverflow.com/a/53520917/5817977)  \n",
    "* In order to get url dashboard use [inner function ](https://github.com/dask/distributed/issues/2083#issue-337057906)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Start Dask Client for Dashboard\n",
    "![Dask Dashboard](images/dask_dashboard.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jsber\\.virtualenvs\\dask_pyconil2019-dwj2t3bv\\lib\\site-packages\\distributed\\bokeh\\core.py:74: UserWarning: \n",
      "Port 8787 is already in use. \n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the diagnostics dashboard on a random port instead.\n",
      "  warnings.warn(\"\\n\" + msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:50403\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:50406/status' target='_blank'>http://127.0.0.1:50406/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>8.50 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:50403' processes=4 cores=4>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "# client = Client(n_workers=1, threads_per_worker=4, processes=False, memory_limit='2GB')\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Starting the Dask Client is optional.  In this example we are running on a `LocalCluster`, this  will also provide a dashboard which is useful to gain insight on the computation.  \n",
    "For additional information on [Dask Client see documentation](https://docs.dask.org/en/latest/setup.html?highlight=client#setup)  \n",
    "\n",
    "The link to the dashboard will become visible when you create a client (as shown below).  \n",
    "When running in `Jupyter Lab` an [extenstion](https://github.com/dask/dask-labextension) can be installed to be able to view the various dashboard widgets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "See [documentation for addtional cluster configuration](http://distributed.dask.org/en/latest/local-cluster.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Create 2 DataFrames for comparison: \n",
    "* `Dask framework` is **lazy**  ![lazy python](images/Sleeping-snake.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=30</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01</th>\n",
       "      <td>int32</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-02</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-31</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: make-timeseries, 30 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                   id    name        x        y\n",
       "npartitions=30                                 \n",
       "2000-01-01      int32  object  float64  float64\n",
       "2000-01-02        ...     ...      ...      ...\n",
       "...               ...     ...      ...      ...\n",
       "2000-01-30        ...     ...      ...      ...\n",
       "2000-01-31        ...     ...      ...      ...\n",
       "Dask Name: make-timeseries, 30 tasks"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf = dask.datasets.timeseries() #  Dask comes with builtin dataset samples, we will use this sample for our example. \n",
    "ddf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In order to see the result we need to run [compute()](https://docs.dask.org/en/latest/dataframe-api.html#dask.dataframe.DataFrame.compute) \n",
    " (or `head()` which runs under the hood compute()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:00</th>\n",
       "      <td>949</td>\n",
       "      <td>Laura</td>\n",
       "      <td>-0.523592</td>\n",
       "      <td>-0.692488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:01</th>\n",
       "      <td>1083</td>\n",
       "      <td>Edith</td>\n",
       "      <td>0.931568</td>\n",
       "      <td>0.510529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:02</th>\n",
       "      <td>1005</td>\n",
       "      <td>Tim</td>\n",
       "      <td>-0.424328</td>\n",
       "      <td>-0.696765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:03</th>\n",
       "      <td>1034</td>\n",
       "      <td>Alice</td>\n",
       "      <td>0.202373</td>\n",
       "      <td>0.311415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:04</th>\n",
       "      <td>964</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>-0.043097</td>\n",
       "      <td>0.390466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:05</th>\n",
       "      <td>993</td>\n",
       "      <td>Quinn</td>\n",
       "      <td>0.060435</td>\n",
       "      <td>0.631855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:06</th>\n",
       "      <td>992</td>\n",
       "      <td>Patricia</td>\n",
       "      <td>-0.878349</td>\n",
       "      <td>-0.387187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:07</th>\n",
       "      <td>989</td>\n",
       "      <td>Victor</td>\n",
       "      <td>0.704567</td>\n",
       "      <td>0.923895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:08</th>\n",
       "      <td>1007</td>\n",
       "      <td>Kevin</td>\n",
       "      <td>0.467177</td>\n",
       "      <td>0.589763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:09</th>\n",
       "      <td>989</td>\n",
       "      <td>Michael</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>-0.164473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:10</th>\n",
       "      <td>956</td>\n",
       "      <td>Edith</td>\n",
       "      <td>-0.117116</td>\n",
       "      <td>-0.210421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:11</th>\n",
       "      <td>1015</td>\n",
       "      <td>Edith</td>\n",
       "      <td>-0.951554</td>\n",
       "      <td>-0.884312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:12</th>\n",
       "      <td>993</td>\n",
       "      <td>Jerry</td>\n",
       "      <td>0.842099</td>\n",
       "      <td>0.457474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:13</th>\n",
       "      <td>953</td>\n",
       "      <td>Wendy</td>\n",
       "      <td>0.888364</td>\n",
       "      <td>0.809548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:14</th>\n",
       "      <td>1003</td>\n",
       "      <td>Victor</td>\n",
       "      <td>0.603634</td>\n",
       "      <td>0.186218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:15</th>\n",
       "      <td>1008</td>\n",
       "      <td>Ray</td>\n",
       "      <td>-0.412201</td>\n",
       "      <td>0.470688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:16</th>\n",
       "      <td>988</td>\n",
       "      <td>George</td>\n",
       "      <td>-0.919636</td>\n",
       "      <td>0.808074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:17</th>\n",
       "      <td>986</td>\n",
       "      <td>Edith</td>\n",
       "      <td>0.652511</td>\n",
       "      <td>-0.066363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:18</th>\n",
       "      <td>995</td>\n",
       "      <td>Oliver</td>\n",
       "      <td>-0.771899</td>\n",
       "      <td>0.472895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:19</th>\n",
       "      <td>959</td>\n",
       "      <td>Edith</td>\n",
       "      <td>-0.119190</td>\n",
       "      <td>-0.990689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:20</th>\n",
       "      <td>1022</td>\n",
       "      <td>Laura</td>\n",
       "      <td>-0.176433</td>\n",
       "      <td>0.179700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:21</th>\n",
       "      <td>966</td>\n",
       "      <td>Zelda</td>\n",
       "      <td>-0.684731</td>\n",
       "      <td>0.450651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:22</th>\n",
       "      <td>1012</td>\n",
       "      <td>Oliver</td>\n",
       "      <td>0.232408</td>\n",
       "      <td>-0.295939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:23</th>\n",
       "      <td>1036</td>\n",
       "      <td>Oliver</td>\n",
       "      <td>0.885739</td>\n",
       "      <td>-0.047157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:24</th>\n",
       "      <td>1015</td>\n",
       "      <td>Jerry</td>\n",
       "      <td>0.878638</td>\n",
       "      <td>-0.842193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:25</th>\n",
       "      <td>968</td>\n",
       "      <td>Patricia</td>\n",
       "      <td>0.045813</td>\n",
       "      <td>-0.700967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:26</th>\n",
       "      <td>1028</td>\n",
       "      <td>Yvonne</td>\n",
       "      <td>0.210510</td>\n",
       "      <td>-0.159611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:27</th>\n",
       "      <td>1026</td>\n",
       "      <td>Jerry</td>\n",
       "      <td>-0.651575</td>\n",
       "      <td>0.449381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:28</th>\n",
       "      <td>1045</td>\n",
       "      <td>Tim</td>\n",
       "      <td>0.942222</td>\n",
       "      <td>0.339208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:29</th>\n",
       "      <td>1013</td>\n",
       "      <td>Quinn</td>\n",
       "      <td>-0.467207</td>\n",
       "      <td>0.553187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30 23:59:30</th>\n",
       "      <td>1001</td>\n",
       "      <td>Tim</td>\n",
       "      <td>0.711102</td>\n",
       "      <td>-0.048667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30 23:59:31</th>\n",
       "      <td>1011</td>\n",
       "      <td>Laura</td>\n",
       "      <td>-0.306989</td>\n",
       "      <td>-0.296302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30 23:59:32</th>\n",
       "      <td>1018</td>\n",
       "      <td>Kevin</td>\n",
       "      <td>-0.320073</td>\n",
       "      <td>-0.594390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30 23:59:33</th>\n",
       "      <td>995</td>\n",
       "      <td>Ursula</td>\n",
       "      <td>0.093410</td>\n",
       "      <td>-0.233681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30 23:59:34</th>\n",
       "      <td>961</td>\n",
       "      <td>Ray</td>\n",
       "      <td>0.260252</td>\n",
       "      <td>-0.438981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30 23:59:35</th>\n",
       "      <td>967</td>\n",
       "      <td>Patricia</td>\n",
       "      <td>-0.017342</td>\n",
       "      <td>0.195568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30 23:59:36</th>\n",
       "      <td>984</td>\n",
       "      <td>Norbert</td>\n",
       "      <td>-0.092062</td>\n",
       "      <td>-0.005370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30 23:59:37</th>\n",
       "      <td>950</td>\n",
       "      <td>Quinn</td>\n",
       "      <td>0.159264</td>\n",
       "      <td>-0.619218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30 23:59:38</th>\n",
       "      <td>1028</td>\n",
       "      <td>Alice</td>\n",
       "      <td>0.067807</td>\n",
       "      <td>0.923271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30 23:59:39</th>\n",
       "      <td>980</td>\n",
       "      <td>Oliver</td>\n",
       "      <td>-0.484089</td>\n",
       "      <td>-0.194365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30 23:59:40</th>\n",
       "      <td>1062</td>\n",
       "      <td>Zelda</td>\n",
       "      <td>-0.244103</td>\n",
       "      <td>-0.484475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30 23:59:41</th>\n",
       "      <td>1024</td>\n",
       "      <td>Michael</td>\n",
       "      <td>-0.437031</td>\n",
       "      <td>-0.405065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30 23:59:42</th>\n",
       "      <td>952</td>\n",
       "      <td>Laura</td>\n",
       "      <td>-0.073409</td>\n",
       "      <td>-0.452218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30 23:59:43</th>\n",
       "      <td>971</td>\n",
       "      <td>Quinn</td>\n",
       "      <td>-0.816702</td>\n",
       "      <td>0.286934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30 23:59:44</th>\n",
       "      <td>983</td>\n",
       "      <td>Patricia</td>\n",
       "      <td>0.262607</td>\n",
       "      <td>-0.169346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30 23:59:45</th>\n",
       "      <td>999</td>\n",
       "      <td>Dan</td>\n",
       "      <td>0.942622</td>\n",
       "      <td>0.710668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30 23:59:46</th>\n",
       "      <td>968</td>\n",
       "      <td>Michael</td>\n",
       "      <td>0.567958</td>\n",
       "      <td>-0.255061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30 23:59:47</th>\n",
       "      <td>996</td>\n",
       "      <td>George</td>\n",
       "      <td>0.532200</td>\n",
       "      <td>-0.699011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30 23:59:48</th>\n",
       "      <td>969</td>\n",
       "      <td>Norbert</td>\n",
       "      <td>-0.384417</td>\n",
       "      <td>0.894581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30 23:59:49</th>\n",
       "      <td>1014</td>\n",
       "      <td>Laura</td>\n",
       "      <td>-0.507548</td>\n",
       "      <td>0.062992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30 23:59:50</th>\n",
       "      <td>964</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>-0.335446</td>\n",
       "      <td>-0.364490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30 23:59:51</th>\n",
       "      <td>966</td>\n",
       "      <td>Michael</td>\n",
       "      <td>0.749185</td>\n",
       "      <td>0.749555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30 23:59:52</th>\n",
       "      <td>990</td>\n",
       "      <td>Quinn</td>\n",
       "      <td>0.561464</td>\n",
       "      <td>0.275494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30 23:59:53</th>\n",
       "      <td>1007</td>\n",
       "      <td>Oliver</td>\n",
       "      <td>-0.587726</td>\n",
       "      <td>0.413966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30 23:59:54</th>\n",
       "      <td>961</td>\n",
       "      <td>Edith</td>\n",
       "      <td>0.390330</td>\n",
       "      <td>-0.291483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30 23:59:55</th>\n",
       "      <td>1019</td>\n",
       "      <td>Alice</td>\n",
       "      <td>0.653564</td>\n",
       "      <td>-0.682104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30 23:59:56</th>\n",
       "      <td>961</td>\n",
       "      <td>Alice</td>\n",
       "      <td>-0.942559</td>\n",
       "      <td>0.826501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30 23:59:57</th>\n",
       "      <td>974</td>\n",
       "      <td>Dan</td>\n",
       "      <td>0.938047</td>\n",
       "      <td>0.848056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30 23:59:58</th>\n",
       "      <td>1001</td>\n",
       "      <td>Ray</td>\n",
       "      <td>-0.707253</td>\n",
       "      <td>-0.956773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30 23:59:59</th>\n",
       "      <td>991</td>\n",
       "      <td>Ingrid</td>\n",
       "      <td>-0.611749</td>\n",
       "      <td>-0.440235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2592000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id      name         x         y\n",
       "timestamp                                              \n",
       "2000-01-01 00:00:00   949     Laura -0.523592 -0.692488\n",
       "2000-01-01 00:00:01  1083     Edith  0.931568  0.510529\n",
       "2000-01-01 00:00:02  1005       Tim -0.424328 -0.696765\n",
       "2000-01-01 00:00:03  1034     Alice  0.202373  0.311415\n",
       "2000-01-01 00:00:04   964     Sarah -0.043097  0.390466\n",
       "2000-01-01 00:00:05   993     Quinn  0.060435  0.631855\n",
       "2000-01-01 00:00:06   992  Patricia -0.878349 -0.387187\n",
       "2000-01-01 00:00:07   989    Victor  0.704567  0.923895\n",
       "2000-01-01 00:00:08  1007     Kevin  0.467177  0.589763\n",
       "2000-01-01 00:00:09   989   Michael  0.009290 -0.164473\n",
       "2000-01-01 00:00:10   956     Edith -0.117116 -0.210421\n",
       "2000-01-01 00:00:11  1015     Edith -0.951554 -0.884312\n",
       "2000-01-01 00:00:12   993     Jerry  0.842099  0.457474\n",
       "2000-01-01 00:00:13   953     Wendy  0.888364  0.809548\n",
       "2000-01-01 00:00:14  1003    Victor  0.603634  0.186218\n",
       "2000-01-01 00:00:15  1008       Ray -0.412201  0.470688\n",
       "2000-01-01 00:00:16   988    George -0.919636  0.808074\n",
       "2000-01-01 00:00:17   986     Edith  0.652511 -0.066363\n",
       "2000-01-01 00:00:18   995    Oliver -0.771899  0.472895\n",
       "2000-01-01 00:00:19   959     Edith -0.119190 -0.990689\n",
       "2000-01-01 00:00:20  1022     Laura -0.176433  0.179700\n",
       "2000-01-01 00:00:21   966     Zelda -0.684731  0.450651\n",
       "2000-01-01 00:00:22  1012    Oliver  0.232408 -0.295939\n",
       "2000-01-01 00:00:23  1036    Oliver  0.885739 -0.047157\n",
       "2000-01-01 00:00:24  1015     Jerry  0.878638 -0.842193\n",
       "2000-01-01 00:00:25   968  Patricia  0.045813 -0.700967\n",
       "2000-01-01 00:00:26  1028    Yvonne  0.210510 -0.159611\n",
       "2000-01-01 00:00:27  1026     Jerry -0.651575  0.449381\n",
       "2000-01-01 00:00:28  1045       Tim  0.942222  0.339208\n",
       "2000-01-01 00:00:29  1013     Quinn -0.467207  0.553187\n",
       "...                   ...       ...       ...       ...\n",
       "2000-01-30 23:59:30  1001       Tim  0.711102 -0.048667\n",
       "2000-01-30 23:59:31  1011     Laura -0.306989 -0.296302\n",
       "2000-01-30 23:59:32  1018     Kevin -0.320073 -0.594390\n",
       "2000-01-30 23:59:33   995    Ursula  0.093410 -0.233681\n",
       "2000-01-30 23:59:34   961       Ray  0.260252 -0.438981\n",
       "2000-01-30 23:59:35   967  Patricia -0.017342  0.195568\n",
       "2000-01-30 23:59:36   984   Norbert -0.092062 -0.005370\n",
       "2000-01-30 23:59:37   950     Quinn  0.159264 -0.619218\n",
       "2000-01-30 23:59:38  1028     Alice  0.067807  0.923271\n",
       "2000-01-30 23:59:39   980    Oliver -0.484089 -0.194365\n",
       "2000-01-30 23:59:40  1062     Zelda -0.244103 -0.484475\n",
       "2000-01-30 23:59:41  1024   Michael -0.437031 -0.405065\n",
       "2000-01-30 23:59:42   952     Laura -0.073409 -0.452218\n",
       "2000-01-30 23:59:43   971     Quinn -0.816702  0.286934\n",
       "2000-01-30 23:59:44   983  Patricia  0.262607 -0.169346\n",
       "2000-01-30 23:59:45   999       Dan  0.942622  0.710668\n",
       "2000-01-30 23:59:46   968   Michael  0.567958 -0.255061\n",
       "2000-01-30 23:59:47   996    George  0.532200 -0.699011\n",
       "2000-01-30 23:59:48   969   Norbert -0.384417  0.894581\n",
       "2000-01-30 23:59:49  1014     Laura -0.507548  0.062992\n",
       "2000-01-30 23:59:50   964   Charlie -0.335446 -0.364490\n",
       "2000-01-30 23:59:51   966   Michael  0.749185  0.749555\n",
       "2000-01-30 23:59:52   990     Quinn  0.561464  0.275494\n",
       "2000-01-30 23:59:53  1007    Oliver -0.587726  0.413966\n",
       "2000-01-30 23:59:54   961     Edith  0.390330 -0.291483\n",
       "2000-01-30 23:59:55  1019     Alice  0.653564 -0.682104\n",
       "2000-01-30 23:59:56   961     Alice -0.942559  0.826501\n",
       "2000-01-30 23:59:57   974       Dan  0.938047  0.848056\n",
       "2000-01-30 23:59:58  1001       Ray -0.707253 -0.956773\n",
       "2000-01-30 23:59:59   991    Ingrid -0.611749 -0.440235\n",
       "\n",
       "[2592000 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Pandas\n",
    "In order to create a `Pandas` dataframe we can use the `compute()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:00</th>\n",
       "      <td>949</td>\n",
       "      <td>Laura</td>\n",
       "      <td>-0.523592</td>\n",
       "      <td>-0.692488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:01</th>\n",
       "      <td>1083</td>\n",
       "      <td>Edith</td>\n",
       "      <td>0.931568</td>\n",
       "      <td>0.510529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:02</th>\n",
       "      <td>1005</td>\n",
       "      <td>Tim</td>\n",
       "      <td>-0.424328</td>\n",
       "      <td>-0.696765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:03</th>\n",
       "      <td>1034</td>\n",
       "      <td>Alice</td>\n",
       "      <td>0.202373</td>\n",
       "      <td>0.311415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:04</th>\n",
       "      <td>964</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>-0.043097</td>\n",
       "      <td>0.390466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id   name         x         y\n",
       "timestamp                                           \n",
       "2000-01-01 00:00:00   949  Laura -0.523592 -0.692488\n",
       "2000-01-01 00:00:01  1083  Edith  0.931568  0.510529\n",
       "2000-01-01 00:00:02  1005    Tim -0.424328 -0.696765\n",
       "2000-01-01 00:00:03  1034  Alice  0.202373  0.311415\n",
       "2000-01-01 00:00:04   964  Sarah -0.043097  0.390466"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf = ddf.compute()  \n",
    "print(type(pdf))\n",
    "pdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Creating a `Dask dataframe` from `Pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In order to utilize `Dask` capablities on an existing `Pandas dataframe` (pdf) we need to convert the `Pandas dataframe` into a `Dask dataframe` (ddf)  with the [from_pandas](https://docs.dask.org/en/latest/dataframe-api.html#dask.dataframe.from_pandas) method. \n",
    "You must supply the number of `partitions` or `chunksize` that will be used to generate the dask dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.core.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:00</th>\n",
       "      <td>949</td>\n",
       "      <td>Laura</td>\n",
       "      <td>-0.523592</td>\n",
       "      <td>-0.692488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:01</th>\n",
       "      <td>1083</td>\n",
       "      <td>Edith</td>\n",
       "      <td>0.931568</td>\n",
       "      <td>0.510529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:02</th>\n",
       "      <td>1005</td>\n",
       "      <td>Tim</td>\n",
       "      <td>-0.424328</td>\n",
       "      <td>-0.696765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:03</th>\n",
       "      <td>1034</td>\n",
       "      <td>Alice</td>\n",
       "      <td>0.202373</td>\n",
       "      <td>0.311415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:04</th>\n",
       "      <td>964</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>-0.043097</td>\n",
       "      <td>0.390466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id   name         x         y\n",
       "timestamp                                           \n",
       "2000-01-01 00:00:00   949  Laura -0.523592 -0.692488\n",
       "2000-01-01 00:00:01  1083  Edith  0.931568  0.510529\n",
       "2000-01-01 00:00:02  1005    Tim -0.424328 -0.696765\n",
       "2000-01-01 00:00:03  1034  Alice  0.202373  0.311415\n",
       "2000-01-01 00:00:04   964  Sarah -0.043097  0.390466"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf2 = dd.from_pandas(pdf, npartitions=10)\n",
    "print(type(ddf2))\n",
    "ddf2.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Partitions in Dask Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Notice that when we created a `Dask dataframe` we needed to supply an argument of `npartitions`.  \n",
    "The number of partitions will assist `Dask` on how it's going to parallelize the computation.  \n",
    "Each partition is a *separate* dataframe. For additional information see [partition documentation](https://docs.dask.org/en/latest/dataframe-design.html?highlight=meta%20utils#partitions)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Using `reset_index()` method we can examin the partitions:  \n",
    "First lets look at the `Pandas` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp    2000-01-01 00:00:00\n",
       "id                           949\n",
       "name                       Laura\n",
       "x                      -0.523592\n",
       "y                      -0.692488\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf2 = pdf.reset_index()\n",
    "# Only 1 row\n",
    "pdf2.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Now lets look at a `Dask` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>949</td>\n",
       "      <td>Laura</td>\n",
       "      <td>-0.523592</td>\n",
       "      <td>-0.692488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>1020</td>\n",
       "      <td>George</td>\n",
       "      <td>0.096655</td>\n",
       "      <td>-0.964252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>994</td>\n",
       "      <td>Oliver</td>\n",
       "      <td>0.330110</td>\n",
       "      <td>0.547710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>1009</td>\n",
       "      <td>Quinn</td>\n",
       "      <td>0.135462</td>\n",
       "      <td>0.201359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-13</td>\n",
       "      <td>978</td>\n",
       "      <td>Victor</td>\n",
       "      <td>0.063773</td>\n",
       "      <td>0.398564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-16</td>\n",
       "      <td>1079</td>\n",
       "      <td>Yvonne</td>\n",
       "      <td>-0.740677</td>\n",
       "      <td>0.205735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-19</td>\n",
       "      <td>948</td>\n",
       "      <td>Jerry</td>\n",
       "      <td>0.065367</td>\n",
       "      <td>-0.164667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-22</td>\n",
       "      <td>1060</td>\n",
       "      <td>Norbert</td>\n",
       "      <td>0.706973</td>\n",
       "      <td>0.018618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-25</td>\n",
       "      <td>980</td>\n",
       "      <td>George</td>\n",
       "      <td>-0.315419</td>\n",
       "      <td>-0.398249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-28</td>\n",
       "      <td>1032</td>\n",
       "      <td>Wendy</td>\n",
       "      <td>0.323498</td>\n",
       "      <td>-0.523070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp    id     name         x         y\n",
       "0 2000-01-01   949    Laura -0.523592 -0.692488\n",
       "0 2000-01-04  1020   George  0.096655 -0.964252\n",
       "0 2000-01-07   994   Oliver  0.330110  0.547710\n",
       "0 2000-01-10  1009    Quinn  0.135462  0.201359\n",
       "0 2000-01-13   978   Victor  0.063773  0.398564\n",
       "0 2000-01-16  1079   Yvonne -0.740677  0.205735\n",
       "0 2000-01-19   948    Jerry  0.065367 -0.164667\n",
       "0 2000-01-22  1060  Norbert  0.706973  0.018618\n",
       "0 2000-01-25   980   George -0.315419 -0.398249\n",
       "0 2000-01-28  1032    Wendy  0.323498 -0.523070"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf2 = ddf2.reset_index() \n",
    "ddf2.loc[0].compute()  # each partition has an index=0\n",
    "# ddf2.loc[0].visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## dataframe.shape  \n",
    "since `Dask` is lazy we cannot get the full shape before running `len`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas shape: (2592000, 4)\n",
      "---------------------------\n",
      "Dask lazy shape: (Delayed('int-0ba98bb8-9fdf-4fe4-9886-55cad7624884'), 4)\n"
     ]
    }
   ],
   "source": [
    "print(f'Pandas shape: {pdf.shape}')\n",
    "print('---------------------------')\n",
    "print(f'Dask lazy shape: {ddf.shape}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask computed shape: 2592000\n"
     ]
    }
   ],
   "source": [
    "print(f'Dask computed shape: {len(ddf.index)}')  # expensive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Now that we have a `dask` (ddf) and a `pandas` (pdf) dataframe we can start to compair the interactions with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Moving from Update to Insert/Delete\n",
    "\n",
    "\n",
    "![inplaceTrue](images/inplace_true.png \"inplace_true\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Dask does not update - thus there are no arguments such as `inplace=True` which exist in Pandas.  \n",
    "For more detials see [issue#653 on github](https://github.com/dask/dask/issues/653)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'name', 'x', 'y'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'name', 'x', 'y'], dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas \n",
    "print(pdf.columns)\n",
    "\n",
    "pdf.rename(columns={'id':'ID'}, inplace=True)\n",
    "\n",
    "pdf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* using `inplace=True` is *not* considerd to be *best practice*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Dask - Error\n",
    "# ddf.rename(columns={'id':'ID'}, inplace=True)\n",
    "# ddf.columns\n",
    "\n",
    "'''\n",
    "---------------------------------------------------------------------------  \n",
    "TypeError                                 Traceback (most recent call last)  \n",
    "<ipython-input-12-3e70ff3a549e> in <module>  \n",
    "      1 # Dask - Error  \n",
    "----> 2 ddf.rename(columns={'id':'ID'}, inplace=True)  \n",
    "      3 ddf.columns  \n",
    "TypeError: rename() got an unexpected keyword argument 'inplace'  \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'name', 'x', 'y'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'name', 'x', 'y'], dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dask or Pandas\n",
    "print(ddf.columns)\n",
    "ddf = ddf.rename(columns={'id':'ID'})\n",
    "ddf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data manipilations  \n",
    "There are several diffrences when manipulating data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loc - Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:07</th>\n",
       "      <td>989</td>\n",
       "      <td>Victor</td>\n",
       "      <td>0.704567</td>\n",
       "      <td>923894.616916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:14</th>\n",
       "      <td>1003</td>\n",
       "      <td>Victor</td>\n",
       "      <td>0.603634</td>\n",
       "      <td>186217.826416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ID    name         x              y\n",
       "timestamp                                                 \n",
       "2000-01-01 00:00:07   989  Victor  0.704567  923894.616916\n",
       "2000-01-01 00:00:14  1003  Victor  0.603634  186217.826416"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_cond = (pdf['x']>0.5) & (pdf['x']<0.8)\n",
    "\n",
    "pdf.loc[mask_cond, ['y']] = pdf['y']* 100\n",
    "pdf[mask_cond].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dask - use mask/where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error\n",
    "# cond_dask = (ddf['x']>0.5) & (ddf['x']<0.8)\n",
    "# ddf.loc[cond_dask, ['y']] = ddf['y']* 100\n",
    "\n",
    "'''\n",
    "> TypeError                                 Traceback (most recent call last)  \n",
    "> <ipython-input-16-2bbb2ae570bd> in <module> \n",
    ">       2 # Error  \n",
    "> ----> 3 ddf.loc[cond_dask, ['y']] = ddf['y']* 100  \n",
    "> TypeError: '_LocIndexer' object does not support item assignment  \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:07</th>\n",
       "      <td>989</td>\n",
       "      <td>Victor</td>\n",
       "      <td>0.704567</td>\n",
       "      <td>9238.946169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:14</th>\n",
       "      <td>1003</td>\n",
       "      <td>Victor</td>\n",
       "      <td>0.603634</td>\n",
       "      <td>1862.178264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ID    name         x            y\n",
       "timestamp                                               \n",
       "2000-01-01 00:00:07   989  Victor  0.704567  9238.946169\n",
       "2000-01-01 00:00:14  1003  Victor  0.603634  1862.178264"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_dask = (ddf['x']>0.5) & (ddf['x']<0.8)\n",
    "\n",
    "ddf['y'] = ddf['y'].mask(cond_dask, ddf['y']* 100)\n",
    "ddf[cond_dask].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[dask mask documentation](https://docs.dask.org/en/latest/dataframe-api.html#dask.dataframe.DataFrame.mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Meta argument\n",
    "\n",
    "> `meta` is the prescription of the names/types of the computation output   \n",
    "[see stack overflow answer](https://stackoverflow.com/questions/44432868/dask-dataframe-apply-meta)\n",
    "\n",
    "![crystal python](images/crystalBallsnake.png \"crystal snake\")\n",
    "Since `Dask` creates a DAG for the computation it requires to understand what are the outputs of each calculation (see [meta documentation](https://docs.dask.org/en/latest/dataframe-design.html?highlight=meta%20utils#metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pdf['initials'] = pdf['name'].apply(lambda x: x[0]+x[1])\n",
    "pdf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ddf['initials'] = ddf['name'].apply(lambda x: x[0]+x[1])\n",
    "ddf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Describe the outcome type of the calculation\n",
    "meta_cal = pd.Series(object, name='initials')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf['initials'] = ddf['name'].apply(lambda x: x[0]+x[1]\n",
    "                                    , meta = meta_cal)\n",
    "ddf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def func(row, col1, col2):\n",
    "    if (row[col1]> 0):\n",
    "        return row[col1] * 1000  \n",
    "    else:\n",
    "        return row[col2] * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddf['z'] = ddf.apply(func, args=('coor_x', 'coor_y'), axis=1, meta=('z', 'float'))\n",
    "ddf['z'] = ddf.apply(func,args=('x', 'y'), axis=1, meta=('z', 'float'))\n",
    "ddf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Map partitions\n",
    "* We can supply an ad-hoc function to run on each partition using the [map_partitions](https://dask.readthedocs.io/en/latest/dataframe-api.html#dask.dataframe.DataFrame.map_partitions) method.   \n",
    "Mainly useful for functions that are not implemented in `Dask` or `Pandas` . \n",
    "* Finally we can return a new `dataframe` which needs to be described in the `meta` argument  \n",
    "The function could also include arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def func2(df, coor_x, coor_y, drop_cols):\n",
    "    df['dist'] =  np.sqrt ( (df[coor_x] - df[coor_x].shift())**2  \n",
    "                           +  (df[coor_y] - df[coor_y].shift())**2 )\n",
    "    df = df.drop(drop_cols, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf2 = ddf.map_partitions(func2\n",
    "                          , coor_x='x'\n",
    "                          , coor_y='y'\n",
    "                          , drop_cols=['initials', 'z']\n",
    "                          , meta=pd.DataFrame({'ID':'i8'\n",
    "                                              , 'name':str\n",
    "                                              , 'x':'f8'\n",
    "                                              , 'y':'f8'                                              \n",
    "                                              , 'dist':'f8'}, index=[0]))\n",
    "ddf2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Convert index into DateTime column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only Pandas\n",
    "pdf = pdf.assign(times=pd.to_datetime(pdf.index).time)\n",
    "pdf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# ddf = ddf.assign(Time= dask.dataframe.to_datetime(ddf.index, format='%Y-%m-%d'). )\n",
    "ddf = ddf.assign(times= dd.to_datetime(ddf.index).dt.time\n",
    "                , dates = dd.to_datetime(ddf.index).dt.date)                 \n",
    "ddf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Dask or Pandas\n",
    "ddf = ddf.assign(times=ddf.index.astype('M8[ns]'))\n",
    "ddf['dates'] = ddf['times'].dt.date\n",
    "ddf['times'] = ddf['times'].dt.time\n",
    "ddf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Drop NA on column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas\n",
    "pdf = pdf.assign(colna = None)\n",
    "print(pdf.head(2))\n",
    "pdf = pdf.dropna(axis=1, how='all')\n",
    "print(pdf.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In odrer for `Dask` to drop a column with all `na` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dask\n",
    "ddf = ddf.assign(colna = None)\n",
    "# check if all values in column are Null - expensive\n",
    "if ddf.colna.isnull().all().compute() == True:   \n",
    "    ddf = ddf.drop(labels=['colna'],axis=1)\n",
    "print(ddf.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##  Reset Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas\n",
    "pdf = pdf.reset_index(drop=True)\n",
    "pdf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dask\n",
    "ddf = ddf.reset_index()\n",
    "ddf = ddf.drop(labels=['timestamp'], axis=1 )\n",
    "ddf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Read / Save files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with `pandas` and `dask` preferable try and work with [parquet](https://docs.dask.org/en/latest/dataframe-best-practices.html?highlight=parquet#store-data-in-apache-parquet-format).  \n",
    "Even so when working with `Dask` - the files can be read with multiple workers .  \n",
    "Most `kwargs` are applicable for reading and writing files [see documentaion](https://docs.dask.org/en/latest/dataframe-api.html#dask.dataframe.DataFrame.to_csv) (including the option for output file naming).  \n",
    "e.g. \n",
    "ddf = dd.read_csv('data/pd2dd/ddf*.csv', compression='gzip', header=False).  \n",
    "\n",
    "However some are not available such as  `nrows`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas\n",
    "from pathlib import Path\n",
    "output_file = 'pdf_single_file.csv'\n",
    "output_dir = Path('data/')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "pdf.to_csv(output_dir / output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(Path(output_dir).glob('*.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "`Dask`\n",
    "Notice the '*' to allow for multiple file renaming. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dask_dir = Path('data/pd2dd/')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Dask\n",
    "ddf.to_csv(f'{output_dask_dir}/ddf*.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To find the number of partitions which will determine the number of output files use [dask.dataframe.npartitions](https://docs.dask.org/en/latest/dataframe-api.html#dask.dataframe.DataFrame.npartitions)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.npartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "list(Path(output_dask_dir).glob('*.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To change the number of output files use [repartition](https://docs.dask.org/en/latest/dataframe-api.html#dask.dataframe.DataFrame.repartition) which is an expensive operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Read files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For `pandas` it is possible to iterate and concat the files [see answer from stack overflow](https://stackoverflow.com/questions/20906474/import-multiple-csv-files-into-pandas-and-concatenate-into-one-dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Pandas\n",
    "dir_path = Path(r'data/pd2dd')\n",
    "concat_df = pd.concat([pd.read_csv(f) for f in list(dir_path.glob('*.csv'))])\n",
    "len(concat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Dask\n",
    "_ddf = dd.read_csv('data/pd2dd/ddf*.csv')\n",
    "len(_ddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " ## Consider using Persist\n",
    "Since Dask is lazy - it may run the **entire** graph/DAG (again) even if it already run part of the calculation in a previous cell.  Thus use [persist](https://docs.dask.org/en/latest/dataframe-best-practices.html?highlight=parquet#persist-intelligently) to keep the results in memory \n",
    "```python\n",
    "ddf = client.persist(ddf)\n",
    "```\n",
    "This is different from Pandas which once a variable was created it will keep all data in memory.  \n",
    "Additional information can be read in this [stackoverflow issue](https://stackoverflow.com/questions/45941528/how-to-efficiently-send-a-large-numpy-array-to-the-cluster-with-dask-array/45941529#45941529) or see an exampel in [this post](http://matthewrocklin.com/blog/work/2017/01/12/dask-dataframes)   \n",
    "This concept should also  be used when running a code within a script (rather then a jupyter notebook) which incoperates loops within the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ddf = dd.read_csv('data/pd2dd/ddf*.csv')\n",
    "ddf = client.persist(_ddf)\n",
    "ddf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Group By - custom aggregations\n",
    "In addition to the [groupby notebook example](https://github.com/dask/dask-examples/blob/master/dataframes/02-groupby.ipynb)  - \n",
    "this is another example how to try to eliminate the use of `groupby.apply`  \n",
    "In this example we are grouping by columns into unique list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare pandas dataframe\n",
    "pdf = pdf.assign(Time=pd.to_datetime(pdf.index).time)\n",
    "pdf['seconds'] = pdf.Time.astype(str).str[-2:]\n",
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "pdf_gb = pdf.groupby(pdf.name)\n",
    "gp_col = ['ID', 'seconds']\n",
    "list_ser_gb = [pdf_gb[att_col_gr].apply\n",
    "               (lambda x: list(set(x.to_list()))) \n",
    "               for att_col_gr in gp_col]\n",
    "df_edge_att = pdf_gb.size().to_frame(name=\"Weight\")\n",
    "for ser in list_ser_gb:\n",
    "        df_edge_att = df_edge_att.join(ser.to_frame(), how='left')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edge_att.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In any case sometimes using Pandas is more efficiante (assuming that you can load all the data into the RAM).  \n",
    "In this case Pandas is faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def set_list_att(x: dd.Series):\n",
    "        return list(set([item for item in x.values]))\n",
    "ddf['seconds'] = ddf.times.astype(str).str[-2:]\n",
    "ddf = client.persist(ddf)\n",
    "ddf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Dask option1 using apply\n",
    "# notice the meta argument in the apply function\n",
    "df_gb = ddf.groupby(ddf.name)\n",
    "gp_col = ['ID', 'seconds']\n",
    "list_ser_gb = [df_gb[att_col_gr].apply(set_list_att\n",
    "                ,meta=pd.Series(dtype='object', name=f'{att_col_gr}_att')) \n",
    "               for att_col_gr in gp_col]\n",
    "df_edge_att = df_gb.size().to_frame(name=\"Weight\")\n",
    "for ser in list_ser_gb:\n",
    "    df_edge_att = df_edge_att.join(ser.to_frame(), how='left')\n",
    "df_edge_att.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Using [dask custom aggregation](https://docs.dask.org/en/latest/dataframe-api.html?highlight=dropna#dask.dataframe.groupby.Aggregation) is consideribly better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dask\n",
    "import itertools\n",
    "custom_agg = dd.Aggregation(\n",
    "    'custom_agg', \n",
    "    lambda s: s.apply(set), \n",
    "    lambda s: s.apply(lambda chunks: list(set(itertools.chain.from_iterable(chunks)))),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Dask option1 using apply\n",
    "df_gb = ddf.groupby(ddf.name)\n",
    "gp_col = ['ID', 'seconds']\n",
    "list_ser_gb = [df_gb[att_col_gr].agg(custom_agg) for att_col_gr in gp_col]\n",
    "df_edge_att = df_gb.size().to_frame(name=\"Weight\")\n",
    "for ser in list_ser_gb:\n",
    "        df_edge_att = df_edge_att.join(ser.to_frame(), how='left')\n",
    "df_edge_att.head(2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "df_edge_att.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Debugging\n",
    "Debugging may be more challenging since\n",
    "1. when using a client - mutliprocessing is complecated\n",
    "2. sometime introducing a faulty command into a graph (such as in a jupyter notebook) requirues to cache-out the graph and start the process from the begining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Corrupted DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "ddf = dask.datasets.timeseries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns an error\n",
    "def func_dist2(df, coor_x, coor_y):\n",
    "    dist =  np.sqrt ( (df[coor_x] - df[coor_x].shift())^2  \n",
    "                     +  (df[coor_y] - df[coor_y].shift())^2 )\n",
    "    return dist\n",
    "ddf['col'] = ddf.map_partitions(func_dist2, coor_x='x', coor_y='y'\n",
    "                                , meta=('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ddf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Even if the function is currected the DAG is corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still results with an error\n",
    "def func_dist2(df, coor_x, coor_y):\n",
    "    dist =  np.sqrt ( (df[coor_x] - df[coor_x].shift())**2  \n",
    "                     +  (df[coor_y] - df[coor_y].shift())**2 )\n",
    "    return dist\n",
    "ddf['col'] = ddf.map_partitions(func_dist2, coor_x='x', coor_y='y'\n",
    "                                , meta=('float'))\n",
    "ddf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Need to reset the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dask.datasets.timeseries()\n",
    "def func_dist2(df, coor_x, coor_y):\n",
    "    dist =  np.sqrt ( (df[coor_x] - df[coor_x].shift())**2  +  (df[coor_y] - df[coor_y].shift())**2 )\n",
    "#     dist =  np.sqrt ( (df[coor_x] - df[coor_x].shift())^2  +  (df[coor_y] - df[coor_y].shift())^2 )\n",
    "    return dist\n",
    "ddf['col'] = ddf.map_partitions(func_dist2, coor_x='x', coor_y='y', meta=('float'))\n",
    "ddf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary\n",
    "1. `Dask` is lazy but efficient (parallel computing)\n",
    "2. Usefull when comming from a `Pandas` (instead of `pysaprk`) \n",
    "3. Distributed environments - from single laptop to thousands clusters (including visabilty into the computation)\n",
    "4. But beware of:\n",
    "  * missing functionalities from `Pandas` API\n",
    "  * currupted DAGs\n",
    "\n",
    "\n",
    "js.berry@gmail.com\n",
    "\n",
    "https://github.com/sephib/dask_pyconil2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "rise": {
   "enable_chalkboard": true,
   "footer": "Gotcha's from Pandas to Dask - pyconil 2019"
  },
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
